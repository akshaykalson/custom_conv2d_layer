# -*- coding: utf-8 -*-
"""Explainable ML_Assignment 8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O2Tz6DXYR_RjcTBHmu98Q_4qd-AJQRnt
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Layer, Input, Conv2D
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.preprocessing import image

# Load CIFAR-10 data
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

# Class names for CIFAR-10
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

# Define the filter
det = np.array([[[[0]],[[1]],[[0]]],
                [[[0]],[[1]],[[0]]],
                [[[0]],[[1]],[[0]]]])

# Custom Conv2D layer with specified filter
class CustomConv2D(Layer):
    def __init__(self, filters, kernel_size, **kwargs):
        super(CustomConv2D, self).__init__(**kwargs)
        self.filters = filters
        self.kernel_size = kernel_size

    def build(self, input_shape):
        self.kernel = self.add_weight("kernel", shape=(*self.kernel_size, input_shape[-1], self.filters), initializer="glorot_normal", trainable=True)
        super(CustomConv2D, self).build(input_shape)

    def call(self, inputs):
        return tf.nn.conv2d(inputs, self.kernel, strides=[1, 1, 1, 1], padding='SAME')

# Input layer
input_layer = Input(shape=(32, 32, 3))

# Custom Conv2D layer with specified filter
custom_conv2d = CustomConv2D(filters=1, kernel_size=(3, 3))(input_layer)

# Build the model
model = Model(inputs=input_layer, outputs=custom_conv2d)

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

# Display model summary
model.summary()

# Plot the output image after the custom Conv2D layer
output_img = model.predict(np.expand_dims(train_images[0], axis=0))

plt.figure(figsize=(6, 6))
plt.subplot(1, 2, 1)
plt.imshow(train_images[0])
plt.title('Original Image')

plt.subplot(1, 2, 2)
plt.imshow(output_img[0, :, :, 0], cmap='gray')
plt.title('Output Image after Custom Conv2D')
plt.show()

# Read and preprocess the image 'Mensa.jpg'
img_path = '/content/Mensa.jpg'
img = image.load_img(img_path, target_size=(32, 32))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array /= 255.0

# Function to apply filter and plot images
def apply_filter_and_plot(model, img_array, filter_name):
    output_img = model.predict(img_array)
    plt.figure(figsize=(6, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(img_array[0])
    plt.title('Original Image')

    plt.subplot(1, 2, 2)
    plt.imshow(output_img[0, :, :, 0], cmap='gray')
    plt.title(f'Filtered Image: {filter_name}')
    plt.show()

# Apply filters to the image
apply_filter_and_plot(model, img_array, 'Smooth')
apply_filter_and_plot(model, img_array, 'Strengthen the Contour')
apply_filter_and_plot(model, img_array, 'Strengthen the Details')
apply_filter_and_plot(model, img_array, 'Sharpen all Edges')
apply_filter_and_plot(model, img_array, 'Sharpen y- or x- Edges')
apply_filter_and_plot(model, img_array, 'Sharpen the Image')
apply_filter_and_plot(model, img_array, '3D Effect')

# Custom Conv2D layer with specified filter
custom_conv2d_1 = CustomConv2D(filters=1, kernel_size=(3, 3), name='custom_conv2d')(input_layer)

# Second Conv2D layer with 64 filters of size 3x3
conv2d_2 = Conv2D(64, (3, 3), activation='relu', name='custom_conv2d_2')(custom_conv2d_1)


# Flatten layer
flatten = Flatten()(conv2d_2)

# Dense layer with weight matrix 256x10
dense = Dense(256, activation='relu')(flatten)
output_layer = Dense(10, activation='softmax')(dense)

# Build the model
model = Model(inputs=input_layer, outputs=output_layer)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Display model summary
model.summary()

# Train the model on CIFAR-10 data
model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))

# Prediction for the image test_images[3:4]
prediction = model.predict(test_images[3:4])
predicted_class = np.argmax(prediction)
print(f"Predicted class: {class_names[predicted_class]}")

# Plot the heatmap of important features
def plot_heatmap(model, image_array):
    class_output = model.output[:, predicted_class]
    last_conv_layer = model.get_layer('custom_conv2d').output

    grads = K.gradients(class_output, last_conv_layer)[0]
    pooled_grads = K.mean(grads, axis=(0, 1, 2))
    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])

    pooled_grads_value, last_conv_layer_value = iterate([image_array])

    for i in range(1):
        last_conv_layer_value[:, :, i] *= pooled_grads_value[i]

    heatmap = np.mean(last_conv_layer_value, axis=-1)
    heatmap = np.maximum(heatmap, 0)
    heatmap /= np.max(heatmap)

    plt.imshow(heatmap, cmap='viridis')
    plt.title('Heatmap of Important Features')
    plt.show()

# Plot heatmap for the image test_images[3:4]
plot_heatmap(model, test_images[3:4])

# Plot RGB images and weights of the first convolutional layer
def visualize_weights(model):
    layer_name = 'custom_conv2d'
    layer_output = model.get_layer(layer_name).output
    intermediate_model = Model(inputs=model.input, outputs=layer_output)

    intermediate_output = intermediate_model.predict(test_images[3:4])

    plt.figure(figsize=(16, 4))

    for i in range(1, 4):
        plt.subplot(1, 4, i)
        plt.imshow(test_images[3])
        plt.title(f'RGB Image Channel {i}')

    plt.subplot(1, 4, 4)
    plt.imshow(intermediate_output[0, :, :, 0], cmap='viridis')
    plt.title('Weights of the First Convolutional Layer')

    plt.show()

# Visualize RGB images and weights
visualize_weights(model)